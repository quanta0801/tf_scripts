{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://github.com/exelban/tensorflow-cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from six.moves import urllib\n",
    "import sys\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "import tarfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_URL = \"http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "DATA_DIR = './data/cifar10_data/'\n",
    "CIFAR10_DIR = 'cifar-10-batches-py/'\n",
    "\n",
    "train_dir = 'cifar10_train'\n",
    "test_dir = 'cifar10_test'\n",
    "\n",
    "NUM_TRAIN_SAMPLES = 50000\n",
    "IMAGE_SIZE = 32\n",
    "NUM_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maybe_download_and_extract():\n",
    "    \"\"\"Download and extract the tarball from Alex's website.\"\"\"\n",
    "    dest_directory = DATA_DIR\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename,\n",
    "                float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "        filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "        print()\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    extracted_dir_path = os.path.join(dest_directory, CIFAR10_DIR)\n",
    "    if not os.path.exists(extracted_dir_path):\n",
    "        tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "        print('Successfully extracted')\n",
    "    else:\n",
    "        print('File present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted\n"
     ]
    }
   ],
   "source": [
    "maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_batch(fpath, label_key='labels'):\n",
    "    \"\"\"Internal utility for parsing CIFAR data.\n",
    "    # Arguments\n",
    "        fpath: path the file to parse.\n",
    "        label_key: key for label data in the retrieve\n",
    "            dictionary.\n",
    "    # Returns\n",
    "        A tuple `(data, labels)`.\n",
    "    \"\"\"\n",
    "    f = open(fpath, 'rb')\n",
    "    d = cPickle.load(f, encoding='bytes')\n",
    "    # decode utf8\n",
    "    d_decoded = {}\n",
    "    for k, v in d.items():\n",
    "        d_decoded[k.decode('utf8')] = v\n",
    "    f.close()\n",
    "    data = d_decoded['data']\n",
    "    labels = d_decoded[label_key]\n",
    "\n",
    "    data = data.reshape(data.shape[0], NUM_CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (50000, 32, 32, 3)\n",
      "y_train: (50000, 1)\n",
      "x_test: (50000, 32, 32, 3)\n",
      "y_test: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = None\n",
    "y_train = None\n",
    "\n",
    "for i in range(1, 6):\n",
    "    fpath = os.path.join(DATA_DIR, CIFAR10_DIR, 'data_batch_' + str(i))\n",
    "    data, labels = load_batch(fpath)\n",
    "    if x_train is None:\n",
    "        x_train = data\n",
    "        y_train = labels\n",
    "    else:\n",
    "        x_train = np.concatenate((x_train, data), axis=0)\n",
    "        y_train = np.concatenate((y_train, labels), axis=0)\n",
    "\n",
    "fpath = os.path.join(DATA_DIR, CIFAR10_DIR, 'test_batch')\n",
    "x_test, y_test = load_batch(fpath)\n",
    "\n",
    "y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "\n",
    "x_train = x_train.transpose(0, 2, 3, 1)\n",
    "x_test = x_test.transpose(0, 2, 3, 1)\n",
    "\n",
    "print(\"x_train:\", str(x_train.shape))\n",
    "print(\"y_train:\", str(y_train.shape))\n",
    "\n",
    "print(\"x_test:\", str(x_train.shape))\n",
    "print(\"y_test:\", str(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "  \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "\n",
    "  Note that the Variable is initialized with a truncated normal distribution.\n",
    "  A weight decay is added only if one is specified.\n",
    "\n",
    "  Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    stddev: standard deviation of a truncated Gaussian\n",
    "    wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "        decay is not added for this Variable.\n",
    "\n",
    "  Returns:\n",
    "    Variable Tensor\n",
    "  \"\"\"\n",
    "  dtype = tf.float16 if FLAGS.use_fp16 else tf.float32\n",
    "  var = _variable_on_cpu(\n",
    "      name,\n",
    "      shape,\n",
    "      tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))\n",
    "  if wd is not None:\n",
    "    weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "    tf.add_to_collection('losses', weight_decay)\n",
    "  return var"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
